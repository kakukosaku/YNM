# Garbage Collection, GC

## Overview

Understanding how GC works can help you write better and faster programs.

agnostic

- Reference Counting
- Generational gc
- Mark and Sweep Algorithm

Language Specific:

- Java
- Python: Know [Memory model](#python-memory-model) first, then [GC](#python-gc)

Ref:

1. https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)
2. https://en.wikipedia.org/wiki/Reference_counting
3. https://www.geeksforgeeks.org/mark-and-sweep-garbage-collection-algorithm/
4. https://rushter.com/blog/python-memory-managment/
5. https://rushter.com/blog/python-garbage-collector/
6. https://stackify.com/python-garbage-collection/
7. https://pythoninternal.wordpress.com/2014/08/04/the-garbage-collector/
8. https://www.artima.com/insidejvm/ed2/gc.html
9. https://www.quora.com/How-does-garbage-collection-in-Python-work-What-are-the-pros-and-cons#

### Python

#### Python Memory Model

åœ¨äº†è§£GCä¹‹å‰, éœ€è¦é¦–å…ˆæ˜Žç™½å®ƒçš„å†…å­˜åˆ†é…æ¨¡åž‹.

Everything in Python is an object. Some objects can hold other objects, such as lists, tuples, dicts, classes, etc. Because of dynamic Python's nature, such an approach requires a lot of small memory allocations. To speed-up memory operations and reduce fragmentation Python uses a special manager on top of the general-purpose allocator, called PyMalloc.

https://github.com/python/cpython/blob/ad051cbce1360ad3055a048506c09bc2a5442474/Objects/obmalloc.c#L534

![hierarchical model](https://rushter.com/static/uploads/img/memory_layers.svg)

**Small object allocation**

> To reduce overhead for small objects (less than 512 bytes) Python sub-allocates big blocks of memory. Larger objects are routed to standard C allocator. Small object allocator uses three levels of abstraction â€” arena, pool, and block.

ä¸ºäº†å‡å°‘å°å¯¹è±¡åˆ†é…çš„æ¶ˆè€—(less than 512 bytes), Pythonä¼šä¸ºå¤§å—å†…å­˜åˆ†é…å­ç©ºé—´ã€‚ è¾ƒå¤§çš„å¯¹è±¡å°†è·¯ç”±åˆ°æ ‡å‡†Cåˆ†é…å™¨ã€‚ å°å¯¹è±¡åˆ†é…å™¨ä½¿ç”¨ä¸‰ä¸ªæŠ½è±¡çº§åˆ« arena, pool, and block.

Let's start with the smallest structure -- block

**Block**

Block is a chunk of memory of a certain size. Each block can keep only one Python object of a fixed size. The size of the block can vary from 8 to 512 bytes and must be a multiple of eight (i.e., use 8-byte alignment). For convenience, such blocks are grouped in 64 size classes.

too intuitive to no need translate ðŸ™ƒ.

| Request in bytes | Size of allocated block | size class idx |
|------------------|-------------------------|----------------|
| 1-8	           | 8	                     | 0              |
| 9-16	           | 16	                     | 1              |
| 17-24	           | 24	                     | 2              |
| 25-32	           | 32	                     | 3              |
| 33-40	           | 40	                     | 4              |
| 41-48	           | 48	                     | 5              |
| ...	           | ...	                 | ...            |
| 505-512	       | 512	                 | 63             |

**Pool**

A collection of blocks of the same size is called a pool. Normally, the size of the pool is equal to the size of a memory page, i.e., 4Kb.

Limiting pool to the fixed size of blocks helps with fragmentation. If an object gets destroyed, the memory manager can fill this space with a new object of the same size.

poolä¸­å­˜å‚¨çš„æ˜¯ç›¸åŒå¤§å°çš„block!, pool ä¹‹é—´ä»¥double linked listè¿žæŽ¥.

Each pool has a special header structure, which is defined as follows:

```c
/* Pool for small blocks. */
struct pool_header {
    union { block *_padding;
            uint count; } ref;          /* number of allocated blocks    */
    block *freeblock;                   /* pool's free list head         */
    struct pool_header *nextpool;       /* next pool of this size class  */
    struct pool_header *prevpool;       /* previous pool       ""        */
    uint arenaindex;                    /* index into arenas of base adr */
    uint szidx;                         /* block size class index        */
    uint nextoffset;                    /* bytes to virgin block         */
    uint maxnextoffset;                 /* largest valid nextoffset      */
};
```

> è¯å¤–éŸ³: è®¡ç®—æœºé¢†åŸŸ, åˆ†å±‚, åˆ†å—, ç®€å•çš„æ–¹æ³•èƒŒåŽæ˜¯å¯¹é—®é¢˜æ·±åˆ»çš„è®¤è¯†...

éœ€è¦é¢å¤–å…³æ³¨çš„fields: nextpool & prevpool, ref.count, szidx, freeblock, arenaindex...

The freeblock field is described as follows:

```
Blocks within pools are again carved out as needed.  pool->freeblock points to
the start of a singly-linked list of free blocks within the pool.  When a
block is freed, it's inserted at the front of its pool's freeblock list.  Note
that the available blocks in a pool are *not* linked all together when a pool
is initialized.  Instead only "the first two" (lowest addresses) blocks are
set up, returning the first such block, and setting pool->freeblock to a
one-block list holding the second such block.  This is consistent with that
pymalloc strives at all levels (arena, pool, and block) never to touch a piece
of memory until it's actually needed.

 So long as a pool is in the used state, we're certain there *is* a block
available for allocating, and pool->freeblock is not NULL.  If pool->freeblock
points to the end of the free list before we've carved the entire pool into
blocks, that means we simply haven't yet gotten to one of the higher-address
blocks.  The offset from the pool_header to the start of "the next" virgin
block is stored in the pool_header nextoffset member, and the largest value
of nextoffset that makes sense is stored in the maxnextoffset member when a
pool is initialized.  All the blocks in a pool have been passed out at least
once when and only when nextoffset > maxnextoffset.
```

Therefore, If a block is empty instead of an object, it stores an address of the next empty block. This trick saves a lot of memory and computation.

freeblockæ˜¯ singly-linked list, é€šè¿‡nextoffsetæŒ‡å‘ä¸‹ä¸€æœªä½¿ç”¨block, blockä¸ºç©ºæ—¶, it stores an address of next empty block.

Each pool has three states:

- used
- full
- empty

In order to efficiently manage pools Python uses an additional array called usedpools. It stores pointers to the pools grouped by class.

å›¾ç¤º:

![usedpool](https://rushter.com/static/uploads/img/usedpools.svg)

Note that pools and blocks are not allocating memory directly, instead, they are using already allocated space from arenas.

**Arena**

The arena is a chunk of 256kB memory allocated on the heap, which provides memory for 64 pools.

```c
struct arena_object {
    uintptr_t address;
    block* pool_address;
    uint nfreepools;
    uint ntotalpools;
    struct pool_header* freepools;
    struct arena_object* nextarena;
    struct arena_object* prevarena;
};
```

same as pools connect each, all arenas are linked using doubly linked list.

**Memory deallocation**

Python's small object manager rarely returns memory back to the Operating System.

An arena gets fully released If and only if all the pools in it are empty. For example, it can happen when you use a lot of temporary objects in a short period of time.

Speaking of long-running Python processes, they may hold a lot of unused memory because of this behavior.

**allocation statistics**

You can get allocations statistics by calling sys._debugmallocstats().

[tracemalloc - Trace memory allocations](https://docs.python.org/3/library/tracemalloc.html)

#### Python GC

ä»¥ä¸‹å…³äºŽGCçš„æè¿°åŸºäºŽ Python 3.6.

**Memory management**

æ ‡å‡†CPythonå®žçŽ°çš„åžƒåœ¾å›žæ”¶å™¨ä¸»è¦æœ‰2éƒ¨åˆ†, the [reference counting](https://en.wikipedia.org/wiki/Reference_counting) collector and the generational garbage collector, know as [gc module](https://docs.python.org/3.6/library/gc.html)

å¼•ç”¨è®¡æ•°æ³•(reference counting)éžå¸¸é«˜æ•ˆ, ä½†æ— æ³•è§£å†³å¾ªçŽ¯å¼•ç”¨(reference cycles), æ‰€ä»¥Pythonä¹Ÿæä¾›äº†è¾…åŠ©ç®—æ³• - åˆ†ä»£å¾ªçŽ¯GCç®—æ³•(generational cyclic GC, that specifically deals with reference cycles).

> The reference counting module is fundamental to Python and can't be disabled, whereas the cyclic GC is optional and can be invoked manually.

æ³¨æ„, reference counting module æ˜¯Pythonçš„åŸºç¡€åŠŸèƒ½, æ— æ³•ç¦ç”¨, è€Œ generational cyclic GCå´å¯ä»¥æ‰‹åŠ¨ç¦ç”¨, å‚è§ä¸Š gc module.

**Reference counting**

Reference counting is a simple technique in which objects are deallocated when there is no reference to them in a program.

Every variable in Python is a reference (a pointer) to an object and not the actual value itself. For example, the assignment statement just adds a new reference to the right-hand side.

To keep track of references, every object (even integer) has an extra field called reference count that is increased or decreased when a pointer to the object is created or deleted. See Objects, [Types and Reference Counts section](https://docs.python.org/3.6/c-api/intro.html#objects-types-and-reference-counts), for a detailed explanation.

examples, where the reference count increase:

- assignment operator
- argument passing
- appending an object to a list(object's reference will be increased).

examples, where the reference count decrease:

- leave its scope
- del by manual

> If reference counting field reaches zero, CPython automatically calls the object-specific memory deallocation function.
>
> If an object contains references to other objects, then their reference count is automatically decremented too. Thus other objects may be deallocated in turn. 

å½“å¼•ç”¨è®¡æ•°é™ä¸º0, CPython è‡ªåŠ¨è°ƒç”¨å…¶deallocation func, åŒæ—¶decreaseå®ƒæ‰€å¼•ç”¨çš„å¯¹è±¡çš„å¼•ç”¨(å…¶é™ä¸º0æ—¶, åŒç†)

> Variables, which are declared outside of functions, classes, and blocks are called globals. Usually, such variables live until the end of the Python's process.
>
> Thus, the reference count of objects, which are referred by global variables, never drops to zero.

å…¨å±€å¯¹è±¡live until the end of the Python's process. å› æ­¤è¢«å…¨å±€å¯¹è±¡å¼•ç”¨çš„å¯¹è±¡, reference count never drops to zero.

It's important to understand that until your program stays in a block, Python interpreter assumes that all variables inside it are in use. To remove something from memory, you need to either assign a new value to a variable or exit from a block of code. 

In Python, the most popular block of code is a function; this is where most the of garbage collection happens. That is another reason to keep functions small and simple.

The main reason why CPython uses reference counting is historical. There are a lot of debates nowadays about the weaknesses of such a technique. Some people claim that modern garbage collection algorithms can be more efficient without reference counting at all. The reference counting algorithm has a lot of issues, such as circular references, thread locking and memory and performance overhead.

The main advantage of such approach is that the objects can be immediately and easily destroyed after they are no longer needed.

**Generational garbage collector**

![reference cycle](https://rushter.com/static/uploads/img/circularref.svg)

```python
import ctypes
import gc

# We use ctypes moule  to access our unreachable objects by memory address.
class PyObject(ctypes.Structure):
    _fields_ = [("refcnt", ctypes.c_long)]

gc.disable()  # Disable generational gc

lst = []
lst.append(lst)

# Store address of the list
lst_address = id(lst)

# Destroy the lst reference
del lst

object_1 = {}
object_2 = {}
object_1['obj2'] = object_2
object_2['obj1'] = object_1

obj_address = id(object_1)

# Destroy references
del object_1, object_2

# Uncomment if you want to manually run garbage collection process 
# gc.collect()

# Check the reference count
print(PyObject.from_address(obj_address).refcnt)
print(PyObject.from_address(lst_address).refcnt)

# output:
# 1
# 1
```

ä¸Šè¿°ä¾‹å­ä¸­, del è¯­å¥æ‰‹åŠ¨é‡Šæ”¾äº†å¯¹ lstæ‰€æŒ‡å¯¹è±¡çš„å¼•ç”¨, åœ¨Python codeä¸­, å·²æ— æ³•è®¿é—®lstæ‰€æŒ‡å¯¹è±¡, ç„¶è€Œå®ƒä»¬ä»ç„¶å­˜åœ¨åœ¨å†…å­˜ä¸­, é€šè¿‡ `address` ä»å¯è®¿é—®. ä¸”å…¶reference count is 1.

é€šè¿‡ [objgraph](https://mg.pov.lt/objgraph/) module you can visually explore such relations

Reference cycles can only occur in container objects (i.e., in objects that can contain other objects), such as lists, dictionaries, classes, tuples. Garbage collector does not track all immutable types except for a tuple. Tuples and dictionaries containing only immutable objects can also be untracked depending on certain conditions. Thus, the reference counting technique handles all non-circular references.

**When does the generational GC trigger**

> Unlike reference counting, cyclic GC does not work in real-time and runs periodically. To reduce the frequency of GC calls and pauses CPython uses various heuristics.
>
> The GC classifies container objects into three generations. Every new object starts in the first generation. If an object survives a garbage collection round, it moves to the older (higher) generation. Lower generations are collected more often than higher. Because most of the newly created objects die young, it improves GC performance and reduces the GC pause time.
> 
> In order to decide when to run, each generation has an individual counter and threshold. The counter stores the number of object allocations minus deallocations since the last collection. Every time you allocate a new container object, CPython checks whenever the counter of the first generation exceeds the threshold value. If so Python initiates the Ñollection process.

1. ä¸åƒå¼•ç”¨è®¡æ•°, åˆ†ä»£å›žæ”¶å‘¨æœŸæ€§æ‰§è¡Œ(æ¯ä¸€ä»£éƒ½æœ‰è§¦å‘æ¡ä»¶, each generation has an individual counter and thrshold.)
2. åˆ†ä»£å›žæ”¶å°†Container objectsåˆ†ä¸ºä¸‰ä»£. æ–°åˆ›å»ºçš„å¯¹è±¡åœ¨fisrt generation. å­˜æ´»äº†ä¸€ä¸ªGCå‘¨æœŸ, ç§»å…¥ä¸‹ä¸€ä»£. è¾ƒå¹´è½»çš„ä»£ä¼šè¢«æ›´é¢‘ç¹GC, because most of the newly created object die young.

more detail:

If we have two or more generations that currently exceed the threshold, GC chooses the oldest one. That is because oldest generations are also collecting all previous (younger) generations. To reduce performance degradation for long-living objects the third generation has [additional requirements](https://github.com/python/cpython/blob/051295a8c57cc649fa5eaa43526143984a147411/Modules/gcmodule.c#L94) in order to be chosen.

The standard threshold values are set to (700, 10, 10) respectively, but you can always check them using the gc.get_threshold function.

You can also adjust them for your particular workload by using the gc.get_threshold function.

**How to find reference cycles**

It is hard to explain the reference cycle detection algorithm in a few paragraphs. But basically, GC iterates over each container object and temporarily removes all references to all container objects it references. After full iteration, all objects which reference count lower than two are unreachable from Python's code and thus can be collected.

To fully understand the cycle-finding algorithm I recommend you to read an [original proposal from Neil Schemenauer](http://arctrix.com/nas/python/gc/) and [collect](https://github.com/python/cpython/blob/7d6ddb96b34b94c1cbdf95baa94492c48426404e/Modules/gcmodule.c#L902) function from CPython's source code. Also, the Quora answers and [The Garbage Collector blog post](https://pythoninternal.wordpress.com/2014/08/04/the-garbage-collector/) can be helpful.

Note that, the problem with finalizers, which was described in the original proposal, has been fixed since Python 3.4. You can read about it in the [PEP 442](http://legacy.python.org/dev/peps/pep-0442/).

#### Performance tips

Cycles can easily happen in real life. Typically you encounter them in graphs, linked lists or in structures, in which you need to keep track of relations between objects. If your program has an intensive workload and requires low latency, you need to avoid reference cycles as possible.

To avoid circular references in your code, you can use weak references, that are implemented in the weakref module. Unlike the usual references, the weakref.ref doesn't increase the reference count and returns None if an object was destroyed.

In some cases, it is useful to disable GC and use it manually. The automatic collection can be disabled by calling gc.disable(). To manually run the collection process, you need to use gc.collect().

#### How to find and debug reference cycles

Debugging reference cycles can be very frustrating especially when you use a lot of third-party libraries.

The standard gc module provides a lot of useful helpers that can help in debugging. If you set debugging flags to DEBUG_SAVEALL, all unreachable objects found will be appended to gc.garbage list.

```python
import gc

gc.set_debug(gc.DEBUG_SAVEALL)

print(gc.get_count())
lst = []
lst.append(lst)
list_id = id(lst)
del lst
gc.collect()
for item in gc.garbage:
    print(item)
    assert list_id == id(item)
```

#### Dealing with reference cycles

ref: https://pythoninternal.wordpress.com/2014/08/04/the-garbage-collector/

CPython for this maintains two double-linked lists: one list of objects to be scanned, and a tentatively unreachable list.

1. éœ€è¦æ˜Žç¡®çš„æ˜¯ä¼šäº§ç”Ÿ cycle reference é—®é¢˜çš„æ˜¯container objectsä¹‹é—´/æœ¬èº«çš„å¼•ç”¨é€ æˆå¯¹è±¡å·² unreachable è€Œreference count still not zero. æ‰€ä»¥å½“collectionæ¨¡å—çš„GCå¼€å§‹æ—¶, å°†æ‰€æœ‰container objects it wants to scan on a first list. (é‰´äºŽå¤§å¤šæ•°å¯¹è±¡åº”è¯¥æ˜¯å¯è¾¾çš„, æ‰€ä»¥å…ˆå‡å®šlistä¸­éƒ½æ˜¯å¯è¾¾å¯¹è±¡, å¦‚ä½•åˆ¤å®šä¸ºä¸å¯è¾¾å¯¹è±¡æ¡ä»¶æ»¡è¶³å†ç§»åˆ° unreachable listæ›´åˆç†/é«˜æ•ˆ). é™¤äº†æœ‰ reference_count å¤–, æ¯ä¸ªå¯¹è±¡è¿˜æœ‰ gc_ref(å…¶è¢«åˆå§‹åŒ–ä¸ºreference_count).

![step1](https://pythoninternal.files.wordpress.com/2014/07/python-cyclic-gc-1-new-page.png)

2. ç„¶åŽGCæ‰«ææ¯ä¸ªcontainer objectå¹¶å°†å…¶æ‰€å¼•ç”¨çš„å¯¹è±¡çš„gc_refå‡1([decrements by 1](http://hg.python.org/cpython/file/eafe4007c999/Modules/gcmodule.c#l386)). æ¢å¥è¯è¯´, æˆ‘ä»¬ä»…å…³å¿ƒâ€œobject to scanâ€åˆ—è¡¨ä»¥å¤–çš„å¼•ç”¨(å¦‚å˜é‡),è€Œä¸å…³å¿ƒåˆ—è¡¨ä¸­å…¶ä»–å®¹å™¨å¯¹è±¡çš„å¼•ç”¨ã€‚

![step2](https://pythoninternal.files.wordpress.com/2014/07/python-cyclic-gc-2-new-page.pngk)

3. å†æ¬¡æ‰«ææ¯ä¸ªcontainer objects, å°†gc_refä¸º0çš„æ ‡è®°ä¸º GC_TENTATIVELY_REACHABLE, ç§»è‡³ tentatively unreachable list.

![step3](https://pythoninternal.files.wordpress.com/2014/07/python-cyclic-gc-3-new-page.png)

4. å½“GCæ‰«æ(ç¬¬äºŒæ¬¡è¿‡ç¨‹ä¸­)åˆ°"link1"objectæ—¶, ç”±äºŽå…¶gc_refä¸º1, å®ƒè¢«æ ‡è®°ä¸º GC_REACHABLE.

![step4](https://pythoninternal.files.wordpress.com/2014/07/python-cyclic-gc-4-new-page.png)

5. å½“GCæ‰«æ(ç¬¬äºŒæ¬¡è¿‡ç¨‹ä¸­)é‡åˆ°äº†è¢«æ ‡è®°ä¸º GC_REACHABLE çš„å¯¹è±¡traverses its references to find all the objects that are reachable from itä¹Ÿå°†å…¶æ ‡è®°ä¸ºGC_REACHABLE.(å¦‚link2, link3, link3å°±ä»Ž tentatively unreachable listç§»å‡º)

![step5](https://pythoninternal.files.wordpress.com/2014/07/python-cyclic-gc-5-new-page.png)

#### More info

Most of the garbage collection is done by reference counting algorithm, which we cannot tune at all. So, be aware of implementation specifics, but don't worry about potential GC problems prematurely.

Each implementation of Python uses its own collector. For example, Jyton uses standard Java's gc (since it running on the JVM) , and PyPy uses [Mark and Sweep algorithm](https://www.geeksforgeeks.org/mark-and-sweep-garbage-collection-algorithm/k). The PyPy's gc is more complicated than CPython's and has additional optimizations http://doc.pypy.org/en/release-2.4.x/garbage_collection.html.

#### Optimization #1: limiting the time for each collection

The idea is that most objects have a very short lifespan and can thus be collected shortly after their creation. The flip side is that the older an object, the less likely it is to be unreachable.

The concept of object generation is a common optimization nowadays. The garbage collectors for Java and V8 (the JavaScript engine used in Chrome and Node.js) use a similar concept: young generation / old generation for Java, new-space / old-space for V8.

#### Optimization #2: limiting the number of full collections

The next question is: what triggers garbage collection? Whenever the number of objects in a particular generation gets over a certain threshold (which can be configured through gc.set_threshold()), collection starts. Note that when the GC decides to collect a given generation, it also collects the younger generations (e.g. it would never collect only gen 1 but also gen 0)

As a second optimization, CPython also limits the number of â€œfullâ€ collections, i.e. that are going through all three generations of objects. A full collection is only run when the ratio of objects that have survived the last â€œnon-fullâ€ collection (that is, collection of generations 0 or 1 objects) is greater than 25% the number of objects that have survived the last full collection. This 25% ratio is hard-coded and cannot be configured.

å½“generation 2 å æ¯” generation 0+1 è¶…è¿‡25%æ—¶, è§¦å‘Full GC. hard-code cannot be configured.

#### The danger of finalizers

There is however another issue. In any language, the garbage collectorâ€™s worst enemy is finalizers â€“ user-defined methods which are called when the GC wants to collect an object (in Python a finalizer is created by defining the method __del__). What if a finalizer makes one or more objects reachable again?  This is why, up to Python 3.3, container objects inside a circular reference with a finalizer are never garbage-collected.

example:

```
>>> class MyClass(object):
...     def __del__(self):
...             pass
...
>>> my_obj = MyClass()
>>> my_obj.ref = my_obj
>>> my_obj
<__main__.MyClass object at 0x00000000025FCEF0>

>>> del my_obj
>>> gc.collect()
2
>>> gc.garbage
[<__main__.MyClass object at 0x00000000025FCEF0>]
```



